# 第五章 神经网络
固定基的线性回归和线性分类会受到纬度灾变影响需要手动调节基函数。通常有两种方法解决这个问题，1. SVM首先定义从每个训练数据为中心的基，然后从中选择其中的一个子集，支持向量机是凸优化的。神经网络则是在先设定坐标基数量，然后再训练过程中自适应。神经网络模型比SVM更为紧凑计算更快，付出的代价是，神经网络是非凸优化
## 5.1 前向传播方程
线性模型中:

$$ y(w,x) = f(\sum_{j=i}w_j\phi_j(x) )$$

本节的主要目标是使的 $\phi_j$ 依赖参数使得它能在学习时自我调节。

前向传播方程为：
$$a_j = \sum_{i=1}^Dw_{ji}^{(1)}x_i + w_{j0}^{(1)}$$ 
$$z_j = h(a_j)$$  
$$a_k = \sum_{j=1}^Mw_{jk}^{(2)}z_j + w_{k0}^{(2)}$$ 
$$y_k = \sigma(a_k)$$ 
其中$x_1 ,...x_D$ 是D 个输入，$a_1,...,a_M$ 是M 个`激活(acitvation)`，$w_{ji}$ 是需要训练的`权重(weight)`,$(1), (2)$ 代表第一层与第二层。$w_{j0}$叫`偏置(bias)`，h(.) 叫做`激活函数(activation function)`。最后输出采用logistic 或者 softmax。
$$y_k = \sigma(\sum_{j=1}^Mw_{kj}^{(2)}h(\sum_{j=1}^Dw_{ji}^{(1)}x_i + w_{j0}^{(1)}) + w_{k0}^{(2)})$$
这个式子叫做前向传播。

虽然叫多层感知器，但是和感知器不同，神经网络是连续函数可以微分。神经网络结构的另一个扩展是引入跨层连接。虽然sigmoid激活函数可以用足够小的参数来模拟跨层链接，但是显示的使用跨层链接通常会取得更好的效果。

神经网络可以模拟任意函数，问题的关键变成了给定一组训练输入如何寻找合适的参数值，幸好基于最大似然和贝叶斯方法，这个问题存在高效解法。

### 5.1.1 权空间对称性
和贝叶斯模型不同，对同样输入输出对，会有多种不同的参数选择可能。比如调换一个隐藏单元的所有输入和输出权重，模型输出不变，M个隐藏单元有$2^M$个等效解。兑换同层两个隐藏单元，模型输出不变，M个隐藏单元有$M!$个等效解

## 5.2 网络训练
对于回归问题，可以将最后输出层取为恒等函数，假设t服从高斯分布有。

$$p(t|X,w,\beta) = \prod_{n=1}^N p(t_n | x_n, w, \beta)$$

取对数得到误差函数
$$E(w) = \frac 1 2 \sum_{n=1}^N (y(x_n, w) - t_n)^2$$

通过求解误差函数可以得到$w_{ML}$，然后$\beta$也可以通过

$$\frac 1 {\beta_{ML}} = \frac 1 N \sum_{n=1}^N \{y_n - t_n\}^2 $$

因为最后一层激活函数为恒等函数所以$y_k = a_k$ 而平方和误差函数的导数 $\frac {dE} {da_k} = y_k - t_k$

考虑二分类问题。给定输入，其输出为一个伯努利方程所以其误差函数就是一个交叉熵误差函数。

$$y=\sigma(a)$$
$$E = - \sum_{n=1}^N \{t_n\ln y_n + (1-t_n) \ln (1 - y_n) \}$$
对于分类问题使用交叉熵而不是平方和误差损失函数会使的收敛更快，泛化性更好。

最后考虑多分类问题。使用1-of-K表示类别，网络的输出可以表示为$y_k(x,w) = p(t_k=1|x)$ 因此误差函数为

$$E(w)= -\sum_{n=1}^N \sum_{k=1}^K t_{nk} \ln y_k(x_n,w)$$
而输出单位函数为 softmax函数。

### 5.2.1 参数优化
$E(w)$的最小值出现在$\triangledown E(w)$为0的地方，而梯度为0的地方可能是极大值点，极小值点或者鞍点。神经网络每个最小值都有多个等价最小值，还有很多不等价局部极小值。全局最小值一般无法找到，而局部极小值往往也拥有不错的效果，所以优化方法为迭代优化寻找局域极小值。因为函数的解析解无法求得，连续非线性函数往往使用迭代方法求极小值。

$$W^{(n+1)} = W^{(n)} + \triangle w^{(n+1)}$$

### 5.2.2 局域二次近似
对误差方程进行泰勒展开：
$$E(W) \simeq E(w_0) + (w -w_0)^Tb + \frac 1 2 (w - w_0)H(w-w_0)$$
其中b为E在$w_0$处的梯度
$$b=\triangledown E|_{w=\hat w}$$
而H为E在$w_0$处的Hessin矩阵

$$H=\triangledown \triangledown E|_{w=\hat w}$$
在局部极小值有 
$$E(w) = E(w^*) + \frac 1 2 (w - w^*) H (w - w^*)$$
本征值分解 
$$Hu_i = \lambda_i u_i $$
$$w-w^* = \sum_i a_i\mu_i$$
$$E(w) = E(w^*)+\frac1 2 \sum_i \lambda_i \alpha_i^2$$
因为是极小值所以每个$\lambda$都为正。H为**正定positive definite**矩阵。

### 5.2.3 梯度信息
在误差函数的二次近似中W个参数，有$W^2$个独立元素。要完全求解需要收集$w^2$条信息。使用梯度计算每次会带来W条信息，所以需要迭代W步，而每次反向传播需要进行W次更新。所以最后计算复杂度为$O(W^2)$

### 5.2.4 梯度下降最优化
最简单的使用梯度信息的方法是
$$W^{(n+1)} = W^{(n)} - \tau\triangledown w^{(n)}$$
不过这个方法效率低下，共轭梯度，或者拟牛顿法都能更高效的解决问题。与梯度下降不同，这些方法每次迭代都会减小，除非达到极小值。为了寻找全局最小值，可以考虑从多个初始位置开始迭代。梯度下降的在线版本，叫在线梯度下降或者随机梯度下降，此时每次更新权重只依赖一个数据点。在线方法可以有效避免数据冗余，相比批量更新。

## 5.3 误差反向传播
反向传播的一个重要贡献是提供了一个高效计算误差相对权重导数的方法。

### 5.3.1 误差函数导数的计算
反向传播公式
$$\delta_j = h'(a_j)\sum_k w_{kj} \delta_k$$
> 注意反向传播计算的是到某一层的误差，要计算层内参数该变量还要乘以该层正向传播时的数值
全过程为
- 对于网络的一个输入向量$x_n$，使用公式进行正向传播，找到所有隐含单元和输出单元的激活。
- 使用上面公式计算所有输出单元的$\delta_k$。
- 使用公式反向传播，获得网络中所有隐含单元的$\delta_j$。
- 使用公式计算导数。

### 5.3.2 一个简单例子
一个误差为平方和误差的两层神经网络激活函数为$tanh(a)$，两层的误差为

$$\delta_k = y_k - t_k$$
$$\delta_j = (1-z_j^2)\sum_{k=1}^K w_{kj}\delta_k$$

两层梯度更新为

$$\frac {\partial E_n}{\partial w_{ji}^{(1)}} = \delta_jx_i$$
$$\frac {\partial E_n}{\partial w_{kj}^{(2)}} = \delta_kz_j$$

### 5.3.3 反向传播的效率
在正向传播中，除非网络特别稀疏，否则权值的数量远远大于神经元数量。计算复杂度主要取决于求和$a_j = \sum_i w_{ij}z_i$ 整体计算开销为 $O(W)$
如果使用数值微分的方法，每个数值导数计算要 $O(W)$ 而每个数值导数单独计算，总复杂度为$O(W^2)$
计算使用反向传播比较快，但是验证的时候使用数值微分，这样准确率高。

### 5.3.4 Jacobian 矩阵
Jacobian 矩阵也可以使用反向传播计算，它的值就是网络输出关于输入的导数
$$J_{ki}= \frac {\partial y_k} {\partial x_i}$$
计算方法等同之前反向传播

## 5.4 Hessian 矩阵
Hessian矩阵二阶导数的作用：
1. 辅助一些非线性优化算法，这些算法是基于误差曲面的二次性质的。
2. 训练集一些小变化时的重训练算法理论基础。
3. 用来发现不那么重要的参数，进行网络纯化。
4. 贝叶斯网络拉普拉斯近似的核心。它的逆矩阵用来确定训练过的神经网络的预测分布，它的特征值确定了超参数的值，它的行列式用来计算模型证据。

反向传播也可以用来计算二阶导数，因为Hessian矩阵有$O(W^2)$个参数所以它的计算复杂度为$O(W^2)$

### 5.4.1 对角近似
为了方便计算矩阵的逆，一个简单近似是将Hessian矩阵当成对角矩阵处理。此时有
$$\frac {\partial^2 E_n} {\partial^2w_{ji}^2} = \frac {\partial^2 E_n} {\partial^2a_{j}^2}z_i^2$$
$$\frac {\partial^2 E_n} {\partial^2a_{j}^2} = h'(a)^2\sum_k\sum_{k'}w_{kj}w_{k'j}\frac {\partial^2 E_n} {\partial a_k \partial a_j} + h''(a)\sum_k w_{kj}\frac {\partial^2 E_n} {\partial a_k}$$
忽略非对角元素有
$$\frac {\partial^2 E_n} {\partial^2a_{j}^2} = h'(a)^2\sum_kw_{kj}^2\frac {\partial^2 E_n} {\partial^2 a_k } + h''(a)\sum_k w_{kj}\frac {\partial^2 E_n} {\partial a_k}$$
这个近似下复杂度从$O(W^2)$降低到$O(W)$。

### 5.4.2 外积近似
$$H = \nabla \nabla E  = \sum_{n=1}^N \nabla y_n \nabla y_n + \sum_{n=1}^N (y_n - t_n) \nabla \nabla y_n$$
第二项在$y_n - t_n \simeq 0$ 时还有误差随机互相抵消时可以近似为0。这样近似后
$$H  \simeq \sum_{n=1}^N b_n b_n^T$$ 
其中$b_n = \nabla y_n$这种近似只有在充分训练后的网络才有效。对于logistic sigmoid 误差的圣经网络近似为
$$H  \simeq \sum_{n=1}^N y_n(1-y_n)b_n b_n^T$$ 
n 为第 n 个数据点

### 5.4.3 Hessian 逆矩阵
使用外积近似可以高效计算Hessian矩阵的逆矩阵。考虑顺序更新的点对H的贡献:
$$H_{L+1} = H_L + b_{L+1}b_{L+1}^T$$
利用Woodbury恒等式，计算反向传播的时候可以顺便迭代更新计算Hessian矩阵。
$$H^{-1}_{L+1} = H^{-1}_{L} - \frac{H_L^{-1}b_{L+1}b^T_{L+1}H_{L}^{-1}}{I + b_{L+1}^TH_L^{-1}b_{L+1}}$$
利用这个方法，数据点可以依次使用，

### 5.4.4 有限差
利用二阶微扰方法可以求二阶导数，不过这个方法效率低下需要$O(W^3)$次计算。一般用于检查反向传播的正确性。更为高效的方法是将中心差用于一阶导数。这个方法复杂度为$O(W^2)$。

### 5.4.5 Hessian 矩阵的精确计算
对于一个任意的前馈拓扑结构的网络，Hessian矩阵也可以精确地计算。计算的方法是使用反向传播算法计算一阶导数的推广，同时也保留了计算一阶导数的方法的许多良好的性质，包括计算效率。考虑两层网络定义
$$\delta_k = \frac {\partial E} {\partial a_k }$$
$$M_{kk'} = \frac {\partial^2 E} {\partial a_k \partial a_k'}$$
Hessian矩阵三种情况：
两个权值都在第二层
$$ \frac {\partial^2 E} {\partial a_k^{(1)} \partial a_k^{'(1)}} = x_ix'_ih''(a_j')I_{jj'}\sum_k w_{kj'}^{(2)}\delta_k +x_ix'_ih'(a_j)h'(a_{j'})\sum_k\sum_{k'} w^{(2)}_{k'j'}w^{(2)}_{kj}M_{kk'}$$
两个权值都在第一层
$$ \frac {\partial^2 E} {\partial a_k^{(1)} \partial a_k^{'(2)}} = x_ih'(a_j)(\delta_kI_{j'j} + z_{j'}\sum_{k'} w^{(2)}_{k'j}M_{kk'})$$
两个权值两层都有

### 5.4.6 Hessian 矩阵的快速乘法
通常我们感兴趣的不是Hessian矩阵本身，而是其与其他矩阵乘积，所以很多时候我们可以直接计算乘积矩阵。
$$v^TH = v^T \triangledown (\triangledown E) = R \{ \triangledown E\}$$
可以化简得到
$$R\{ \frac {\partial E}{ \partial w_{kj}} \} = R \{ \delta_k\}z_j + \delta_k R\{z_j \}$$
$$R\{ \frac {\partial E}{ \partial w_{ij}} \} = x_i R \{ \delta_j\}$$

## 5.5 神经网络的正则化
模型中的超参数比如隐含单元数量M的确定可以通过，画出M与验证集误差关系得到，不过更普遍的做法是选择一个较大的M然后通过增加一个正则化误差项控制模型复杂度。最简单的方法是二次正则，$E(W) = E(W) + \frac \lambda 2 W^T W$

### 5.5.1 相容的高斯先验
如果使用简单的二次正则，则对某一层做线性变换则，会导致训练出不同结果。如果要求线性一致性，则必须每一层有单独的正则化常数。

$$p(w) \sim exp ( \ frac 1 2 \sum_k\alpha_k || w ||_k^2 )$$
$$||w||_k^2 = \sum_{j\epsilon W_k} w_j^2$$

### 5.5.2 早停止
训练时，训练集的训练误差一致下降，而测试集的误差先是下降，后来因为过拟合而上升。Early Stopping 在测试集误差最小的时候停止训练，可以得到的效果和参数衰减类似。此时参数还在从较小的值移动向较大的值的路上。

### 5.5.3 不变性
有时候，分类问题有很多不变性，比如图像识别中图像的拉伸，旋转，平移等。
解决不变性的方法有四种：
1. 制造一些变换后的样本。
2. 增加专门的正则化，对不满足不变性的特征进行惩罚性衰减。
3. 手动选择满足不变性的特征。
4. 建立满足不变形的模型。

### 5.5.4 切线传播

某个变换下，假设它是连续的，则变换的模式在D纬空间会扫过一个流形M。曲线M的切线为x变换的切线方向为
$$\tau_n = \frac{ds(x_n, \epsilon)}{d\epsilon}|_{\epsilon = 0}$$
输入进行这个变换后，输出也会有相应变换。
$$ \frac{dy_k}{d\epsilon} |_{\epsilon=0} = \sum_{i=1}^D J_{ki}\tau_i$$
其中J为Jaccobian矩阵，如果我们增加正则项$\hat{E} = E  +\lambda \Omega$其中
$$\Omega = \frac 1 2 \sum_n \sum_k (\sum_{i=1}^D J_{nki}\tau_{ni})^2$$

可以从数学上证明这个方法和制造变换后样本等价。（证明方法，变换后的数据泰勒展开后等于增加了正则项）

### 5.5.5 使用变换后的数据
让模型对于一组变换具有不变性的一种方法是使用原始输入模式的变换后的模式来扩展训练集。这种方法与切线传播的方法密切相关。

### 5.5.6 卷积神经网络
另一种构造对输入变量的变换具有不变性的模型的方法是将不变性的性质融入到神经网络结构的构建中。这是**卷积神经网络(convolutional neural network)**的基础，它被广泛地应用于图像处理领域。 卷积神经网络中，通过下面三种方式:
1. 局部接收场
1. 权值共享
1. 下采样

对图像处理进行了优化。

### 5.5.7 软权值共享
降低具有大量权值参数的网络复杂度的一种方法是将权值分组，然后令分组内的权值相等。这里，我们考虑**软权值共享 (soft weight sharing)**。这种方法中，权值相等的硬限制被替换为一种形式的正则化，其中权值的分组倾向于取近似的值。

将权值分成若干组，每一组都满足高斯先验，总的误差函数为
$$\Omega(w) = - \sum_i \ln ( \sum_i^M \pi_i N \frac {(\mu_j - w_i)}{\sigma_j^2} )$$
$$\hat{E(w)} = E(w) + \lambda \Omega(w)$$

可以采用EM方法确定每个参数属于哪个高斯先验，但是更好的方法，是将$\pi_i$当成先验然后引入后验概率。
$$\gamma_j(w) = \frac {\pi_j N(w|\mu_j, \sigma_j^2)}{\sum_k \pi_k N(w| \mu_k, \sigma_k^2)}$$

$$\frac {\partial \hat{E(w)}}{\partial w_i} = \frac {\partial E(w)}{\partial w_i} + \lambda \sum_j \gamma_ j(w_i) \frac {(w_i - \mu_j)}{\sigma_j^2}$$
正则化项的效果是把每个权值拉向第j个高斯分布的中心。而$\mu_j$和$\sigma_j$的倒数则为权值的加权平均与加权方差值。实际使用的时候往往引入
$$\sigma_i^2 = exp (\epsilon_i)$$
这样可以防止 $\sigma$为负数，或者找到多个$\sigma$为0的病态解。

## 5.6 混合密度网络

有时候，数据有多模式，此时用简单回归方法用均值去预测值就会出现较大误差。 此时可以训练混合密度网络，对每种模式求均值作为估计。

$$p(t|x) = \sum_i^K = \pi_k(x) N(t|\mu_k(x), \sigma_k^2(x) I)$$

引入
$$\pi_k(x) = \frac{exp(a_k^{\pi})}{\sum_{l=1}^K exp(a_l^{\pi})}$$
$$\sigma_k(x) = exp(a_k^{\sigma})$$
$$\mu_{kj}(x) = a_{kj}^{\mu}$$
引入
$$\gamma_{nk} = \gamma_k(t_n|x_n) = \frac{\pi_k N_{nk}}{\sum_{l=1}^K\pi_l N_{nk}}$$
$$N_{nk} = N(t_n|\mu_k(x_n), \sigma_k^2(x_n))$$
可以得到
$$\frac {\partial E_n} {\partial a_k^{\pi}} = \pi_k - \gamma_{nk}$$
$$\frac {\partial E_n} {\partial a_k^{\mu}} = \gamma_{nk} \{ \frac {\mu_{kl} - t_{nl}}{\sigma_k^2 }\}$$
$$\frac {\partial E_n} {\partial a_k^{\sigma}} = \gamma_{nk} \{ L - \frac { || t_n - \mu_n ||^2}{\sigma_k^2 }\}$$

## 5.7 贝叶斯神经网络

目前为止，我们对于神经网络的讨论集中于使用最大似然方法来确定网络的参数(权值和偏置)。正则化的最大似然方法可以看成**MAP(maximum posterior)**方法，其中正则化项可以被看成先验参数分布的对数。然而，在贝叶斯方法中，为了进行预测，我们需要对参数的概率分布进行积分或求和。

本节主要采用拉普拉斯近似方法，使用一个以真实后验概率的众数为中心的高斯分布来近似后验概率分布，假设这个高斯分布的协方差很小，从而网络函数关于参数空间的区域中的参数近似是线性关系。

### 5.7.1 后验参数分布

从输入x预测连续变量t，先验后验都为高斯分布。

$$p(w|\alpha) = N(w | 0, \alpha^{-1} I )$$
$$p(D | w, \beta ) = \prod_{n=1}^N N(t_n|y(x_n, w), \beta^{-1}) $$

后验概率
$$p(w|D ) \sim p(w|\alpha) p(D|w, \beta) $$
不是高斯分布，使用拉普拉斯近似可以找到一个高斯近似。首先寻找$w_{MAP}$然后通过公式
$$A^{-1} = - \triangledown \triangledown \ln p(w|D,\alpha, \beta ) = \alpha I + \beta H$$
然后有$p(w|D)=N(w|w_{MAP}, A^{-1})$ 而预测可以由
$$p(t|x, D) = \int p(t|x, w) p(w|D) dw$$
再做近似
$$y(x|w) \sim y (x, x_{MAP}) + g^T (w - w_{MAP})$$
$$g = \triangledown_w y(x,w) |_{w=w_{MAP}}$$
可以得到
$$p(t|x, D, \alpha, \beta) = N (t|y(x, w_{MAP}), \sigma^2(x))$$
$$\sigma^2(x) = \beta^{-1} + g^TA^{-1}g$$

### 5.7.2 超参数最优化
$$\ln p(D|\alpha, \beta) \simeq -E(w_{MAP}) - \frac 1 2 |A| + \frac W 2 \ln \alpha + \frac N 2 \beta - \frac N 2 \ln (2\pi)$$
在模型证据框架中，我们通过最大化$\ln p (D | \alpha \ beta)$ 对 $\alpha$ 和$\beta$进行估计。具体方法与第三章中相同。需要交替地进行超参数α和β的重新估计以及后验概率分布的更新。这些方法中，都需要计算Hessian矩阵的行列式|A|。这在实际应用中会有很大的问题，因为与矩阵的迹不同，行列式对于小的特征值比较敏感，而这些特征值通常很难精确计算。

### 5.7.3 用于分类的贝叶斯神经网络
`参考4.5`加上`5.7.1`中方法，先计算MAP然后近似最后得到:
$$p (t=1|x, D) = \sigma(k(\sigma_a^2), a_{MAP})$$
